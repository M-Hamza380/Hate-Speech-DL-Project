{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Unzip file\n",
    "import zipfile\n",
    "\n",
    "# Test preprocessing related libraries\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "# Punctuation marks\n",
    "import string\n",
    "\n",
    "# Stop words\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# Stemming and Stopwords\n",
    "stemming = nltk.SnowballStemmer('english')\n",
    "stopword = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "imbalanced_data = pd.read_csv(\"./data/imbalanced_data.csv\")\n",
    "raw_data = pd.read_csv(\"./data/raw_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display top & last 5 rows of imbalanced data \n",
    "imbalanced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display top & last 5 rows of raw data \n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove un-neccessary columns from both datasets \n",
    "imbalanced_data.drop(columns=['id'], axis=1, inplace=True)\n",
    "raw_data.drop(columns=['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I made a few strategies to deal with data.\n",
    "\n",
    "### 1. Understanding data\n",
    "### 2. EDA\n",
    "### 3. Data preprocessing\n",
    "### 4. Model building, and evaluation\n",
    "### 5. Model testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understanding Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataExplain:\n",
    "    def __init__(self, df):\n",
    "        self.data = df\n",
    "    \n",
    "    def data_looks(self):\n",
    "        print(f\"\\t\\t\\t How data does looks like\")\n",
    "        print(f\"\\t\\t\\t Top 5 rows of data: \\n\")\n",
    "        print(self.data.head())\n",
    "        print('-'*90, '\\n')\n",
    "        print(f\"\\t\\t\\t Random 5 rows of data: \\n\")\n",
    "        print(self.data.sample(5))\n",
    "        print('-'*90, '\\n')\n",
    "        print(f\"\\t\\t\\t Last 5 rows of data: \\n\")\n",
    "        print(self.data.tail())\n",
    "        print('-'*90, '\\n')\n",
    "\n",
    "    \n",
    "    def columns_and_types(self):\n",
    "        print(f\"\\t\\t\\t Data shape (rows & columns): \\n\")\n",
    "        print(self.data.shape)\n",
    "        print('-'*45, '\\n')\n",
    "        \n",
    "        print(f\"\\t\\t\\t Data columns name: \\n\")\n",
    "        print(self.data.columns)\n",
    "        print('-'*45, '\\n')\n",
    "\n",
    "        print(f\"\\t\\t\\t Data columns types: \\n\")\n",
    "        print(self.data.info())\n",
    "        print('-'*45, '\\n')\n",
    "    \n",
    "    def missing_and_duplicate(self):\n",
    "        print(f\"\\t\\t\\t Data missing values: \\n\")\n",
    "        print(self.data.isnull().sum()*100)\n",
    "        print('-'*45, '\\n')\n",
    "\n",
    "        print(f\"\\t\\t\\t Data duplicate values: \\n\")\n",
    "        print(self.data.duplicated().sum())\n",
    "        print('-'*45, '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class object of imbalanced_data\n",
    "dataexplian = DataExplain(imbalanced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display top, random, and last 5 rows of imbalanced_data\n",
    "dataexplian.data_looks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display shape, columns_name and columns types of imbalanced_data\n",
    "dataexplian.columns_and_types()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display missing and duplicate values in imbalanced_data\n",
    "dataexplian.missing_and_duplicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class object of raw_data\n",
    "dataexplian = DataExplain(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display top, random, and last 5 rows of raw_data\n",
    "dataexplian.data_looks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display shape, columns_name and columns types of raw_data\n",
    "dataexplian.columns_and_types()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display missing and duplicate values in raw_data\n",
    "dataexplian.missing_and_duplicate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imbalanced_data label values\n",
    "imbalanced_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart of imbalanced_data column 'label'\n",
    "imbalanced_data['label'].value_counts().plot(kind= 'bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart imbalanced_data column 'label'\n",
    "labels = imbalanced_data['label'].value_counts().index\n",
    "plt.pie(imbalanced_data['label'].value_counts(), labels=labels, autopct=\"%.2f%%\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "\n",
    "- label 0: no hate\n",
    "- label 1: hate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_data values\n",
    "raw_cols = ['count', 'hate_speech', 'offensive_language', 'neither', 'class']\n",
    "raw_data[raw_cols].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns which are not required\n",
    "raw_data.drop(columns=['count', 'hate_speech', 'offensive_language', 'neither'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_data class unique values\n",
    "raw_data['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_data class values\n",
    "raw_data['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the countplot on raw_data 'class' columns\n",
    "sns.countplot(data= raw_data, x='class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart raw_data column 'class'\n",
    "labels = raw_data['class'].value_counts().index\n",
    "plt.pie(raw_data['class'].value_counts(), labels=labels, autopct=\"%.2f%%\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "\n",
    "- class 0: hate\n",
    "- class 1: abusive\n",
    "- class 2: no hate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the values of class 1 into class 0.\n",
    "raw_data[raw_data['class']==0]['class']==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the value in class 0\n",
    "raw_data[raw_data['class']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the class 0 to class 1 value\n",
    "raw_data['class'].replace({0: 1}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the class 2 to 0\n",
    "raw_data['class'].replace({2: 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the class name into label\n",
    "raw_data.rename(columns= {'class': 'label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the both datasets\n",
    "final_df = pd.concat([imbalanced_data, raw_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class object of final_df\n",
    "dataexplian = DataExplain(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display top, random, and last 5 rows of final_df\n",
    "dataexplian.data_looks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display shape, columns_name and columns types of final_df\n",
    "dataexplian.columns_and_types()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display missing and duplicate values in final_df\n",
    "dataexplian.missing_and_duplicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df label unique values\n",
    "final_df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df label values\n",
    "final_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart of final_df column 'label'\n",
    "final_df['label'].value_counts().plot(kind= 'bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart final_df column 'label'\n",
    "labels = final_df['label'].value_counts().index\n",
    "plt.pie(final_df['label'].value_counts(), labels=labels, autopct=\"%.2f%%\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data preprocessing\n",
    "\n",
    "### Basic Cleanup\n",
    "- Remove HTML tags\n",
    "- Convert Emoji\n",
    "- Spell Checking\n",
    "    - Fast type\n",
    "    - Fat Fingure Type\n",
    "\n",
    "### Basic Text Preparation\n",
    "- Fundamental Basic\n",
    "    - Number of Characters\n",
    "    - Word Tokenization\n",
    "    - Sentence Tokenization\n",
    "\n",
    "- Optional\n",
    "    - Lower Case\n",
    "    - Remove Special Characters, Stop Words, Punctuation, and Digits\n",
    "    - Stemming, Lemmatization\n",
    "    - Language Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch number of characters with punctions, digits, and special characters\n",
    "final_df['num_characters'] = final_df['tweet'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the text data\n",
    "def data_clean(words):\n",
    "    words = str(words).lower()\n",
    "    words = re.sub(r'[^a-zA-Z0-9\\s]', '', words)\n",
    "    words = re.sub('\\[.*?]', \"\", words)\n",
    "    words = re.sub('https?://\\S+|www\\.\\S+', \"\", words)\n",
    "    words = re.sub('<.*?>+', '', words)\n",
    "    words = re.sub('[%s]' % re.escape(string.punctuation), '', words)\n",
    "    words = re.sub('\\n', '', words)\n",
    "    words = re.sub('\\w*\\d\\w*', '', words)\n",
    "    words = [word for word in words.split(\" \") if word not in stopword]\n",
    "    words = [stemming.stem(word) for word in words]\n",
    "    words = \" \".join(words)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['tweet'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean(\" #model   i love u take with u all the time in urÃ°ÂŸÂ“Â±!!! Ã°ÂŸÂ˜Â™Ã°ÂŸÂ˜ÂŽÃ°ÂŸÂ‘Â„Ã°ÂŸÂ‘Â…Ã°ÂŸÂ’Â¦Ã°ÂŸÂ’Â¦Ã°ÂŸÂ’Â¦  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply data_clean function on tweet data\n",
    "final_df['tweet_transformed'] = final_df['tweet'].apply(data_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the whole dataset\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make wordCloud\n",
    "from wordcloud import WordCloud\n",
    "wc = WordCloud(width = 700, height = 700, min_font_size = 10, background_color = 'white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate wordcloud on hate tweets\n",
    "hate_wc = wc.generate(final_df[final_df['label'] == 1]['tweet_transformed'].str.cat(sep= \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph the word cloud of hate tweets\n",
    "plt.figure(figsize=(25,12))\n",
    "plt.imshow(hate_wc)\n",
    "plt.style.use('classic')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate wordcloud on no-hate tweets\n",
    "no_hate_wc = wc.generate(final_df[final_df['label'] == 0]['tweet_transformed'].str.cat(sep= \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph the word cloud of no-hate tweets\n",
    "plt.figure(figsize=(25,12))\n",
    "plt.imshow(no_hate_wc)\n",
    "plt.style.use('classic')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top occuring Words in hate tweets\n",
    "hate_corpus = []\n",
    "\n",
    "for tweet in final_df[final_df['label'] == 1]['tweet_transformed']:\n",
    "    for word in tweet.split():\n",
    "        hate_corpus.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of hate tweets words\n",
    "len(hate_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "a = pd.DataFrame(Counter(hate_corpus).most_common(50))[0]\n",
    "b = pd.DataFrame(Counter(hate_corpus).most_common(50))[1]\n",
    "\n",
    "sns.barplot(x=a, y=b)\n",
    "plt.xticks(rotation= 'vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top occuring Words in no-hate tweets\n",
    "no_hate_corpus = []\n",
    "\n",
    "for tweet in final_df[final_df['label'] == 0]['tweet_transformed']:\n",
    "    for word in tweet.split():\n",
    "        no_hate_corpus.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of no-hate tweets words\n",
    "len(no_hate_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = pd.DataFrame(Counter(no_hate_corpus).most_common(50))[0]\n",
    "d = pd.DataFrame(Counter(no_hate_corpus).most_common(50))[1]\n",
    "\n",
    "sns.barplot(x=c, y=d)\n",
    "plt.xticks(rotation= 'vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into X,y features\n",
    "X = final_df['tweet_transformed']\n",
    "y = final_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split arrays or matrices into random train and test subsets.\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_train), len(y_train))\n",
    "print(len(X_test), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model building, and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import keras library\n",
    "import keras\n",
    "\n",
    "# Tokenization with keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "# Metrics measure\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Sequential model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Embedding, SpatialDropout1D\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Tokenization\n",
    "max_words = 50000\n",
    "max_len = 300\n",
    "\n",
    "tokenizer = Tokenizer(num_words= max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(X_train)\n",
    "sequences_matrix = pad_sequences(sequences, maxlen= max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating model architecture\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 100, input_length= max_len))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(50, dropout= 0.2, recurrent_dropout= 0.2, return_sequences=True))\n",
    "model.add(LSTM(50, dropout=0.1, recurrent_dropout=0.1))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss= 'binary_crossentropy', optimizer= RMSprop(), metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model deatailed summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "history = model.fit(sequences_matrix, y_train, batch_size=64, epochs=2, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test \n",
    "test_sequence = tokenizer.texts_to_sequences(X_test)\n",
    "test_sequence_matrix = pad_sequences(test_sequence, maxlen= max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "model_acc = model.evaluate(test_sequence_matrix, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "y_pred = model.predict(test_sequence_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform prediction\n",
    "res = []\n",
    "\n",
    "for prediction in y_pred:\n",
    "    if prediction[0] < 0.5:\n",
    "        res.append(0)\n",
    "    else:\n",
    "        res.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tokenizer and also save the model if you want\n",
    "import pickle\n",
    "with open('./data/tokenizer.pickle', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f, protocol= pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save('./data/model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_clf = keras.models.load_model('./data/model.h5')\n",
    "with open('./data/tokenizer.pickle', 'rb') as f:\n",
    "    load_token = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_txt = \"!!!!&#8220;@selfiequeenbri: cause I'm tired of you big bitches coming for us skinny girls!!&#8221;\"\n",
    "user_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_test = [data_clean(user_txt)]\n",
    "print(user_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = load_token.texts_to_sequences(user_test)\n",
    "padded = pad_sequences(seq, maxlen= 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = load_clf.predict(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pred < 0.5:\n",
    "    print(\"No Hate\")\n",
    "else:\n",
    "    print(\"Hate and Abusive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
